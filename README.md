# Real-Time Healthcare Lakehouse for Patient Monitoring (Synthea, Faker, Kafka, Spark, Delta Lake, BigQuery)

This project builds a **real-time healthcare data lake and analytics platform** for monitoring patient vitals from simulated **IoT wearable devices**, using a combination of **Synthea** for realistic synthetic patient histories and **Faker** for live streaming vitals. Vital signs like heart rate, temperature, and SpO₂ are streamed via **Apache Kafka**, processed in real time using **Spark Structured Streaming**, and stored in **Delta Lake** using a Bronze–Silver–Gold architecture. Cleaned and aggregated data is loaded into **BigQuery** for analysis and visualized using **Looker**. An **anomaly detection ML model** is integrated to identify abnormal vitals in real time, simulating how healthcare providers can respond to emergencies and monitor patient health at scale.

## Project Goals

- **Simulate realistic patient data using Synthea and Faker**

  Use Synthea to generate full synthetic EHR records and vitals distributions.

  Use Faker-guided scripts to simulate real-time streaming data from IoT devices based on Synthea trends.

- **Ingest real-time vitals from simulated IoT patient devices**

  Stream live patient vitals like heart rate, temperature, SpO₂, and blood pressure using Apache Kafka to mimic a hospital monitoring environment.

- **Stream and process data with Spark Structured Streaming**

  Process Kafka streams with schema enforcement, cleansing, timestamp alignment, and enrichment.

- **Store data in Delta Lake using Bronze, Silver, and Gold architecture**
  - Bronze: Raw Kafka ingestion
  - Silver: Parsed, cleaned, and enriched data
  - Gold: Aggregated metrics with anomaly flags

- **Load curated data into BigQuery for analytics**

  Transfer Gold-layer data into Google BigQuery for scalable querying and reporting.

- **Visualize trends and anomalies with Looker Studio**

  Build dashboards for hospital-wide monitoring, patient-level trends, and anomaly alerts.

- **Apply ML models for real-time anomaly detection**

  Train models on historical Synthea-based data and run inference on real-time streams.

## Architecture

![architecture](https://github.com/user-attachments/assets/c96bc8f2-e121-45a3-b7d3-164284524929)

## Technology Stack

| Layer                   | Tools/Technologies                                         |
|------------------------|------------------------------------------------------------|
| Data Simulation         | Synthea (synthetic EHR), Faker, NumPy, JSON                             |
| Ingestion               | Apache Kafka                                               |
| Streaming               | Apache Spark (Structured Streaming)                        |
| Storage                 | Delta Lake (Parquet + Transaction Logs)                    |
| ML / Anomaly Detection  | PySpark ML, scikit-learn, MLflow |
| Orchestration           | Apache Airflow (ETL)            |
| Query Layer             | Google BigQuery                                            |
| Visualization           | Looker Studio                                              |

## Data Used

### 1. **Synthea-Generated Static Dataset**

- **Source:** `synthea_data/data_for_train.csv`
- **Description:** High-quality synthetic patient data generated by Synthea, representing realistic vitals and clinical conditions.
- **Usage:**
  - Machine learning model training (`RandomForestClassifier`)
  - Feature engineering and baseline distribution reference

**Key Features Used in Training:**

| Feature Name                                                                                  | Description                                             | Type    |
|-----------------------------------------------------------------------------------------------|---------------------------------------------------------|---------|
| `age`                                                                                         | Patient age (derived from date of birth)                | Integer |
| `gender`                                                                                      | Binary encoded gender (0 = Female, 1 = Male)            | Integer |
| `body_mass_index`                                                                             | Body mass index (BMI) in kg/m²                          | Float   |
| `body_temperature`                                                                            | Body temperature in °C                                  | Float   |
| `heart_rate`                                                                                  | Heart rate in beats per minute (bpm)                    | Integer |
| `systolic_blood_pressure`                                                                     | Systolic blood pressure (mmHg)                          | Integer |
| `creatinine`                                                                                  | Creatinine level in mg/dL                               | Float   |
| `alanine_aminotransferase_[enzymatic_activity/volume]_in_serum_or_plasma`                    | Liver enzyme (ALT) level in U/L                         | Float   |
| `glucose`                                                                                     | Blood glucose level in mg/dL                            | Float   |
| `hemoglobin_[mass/volume]_in_blood`                                                           | Hemoglobin concentration in g/dL                        | Float   |
| `leukocytes_[#/volume]_in_blood_by_automated_count`                                           | White blood cell count (10³/μL)                         | Float   |
| `oxygen_saturation_in_arterial_blood`                                                         | Oxygen saturation (SpO₂) percentage                     | Integer |
| `is_ill`                                                                                      | Target label (0 = Healthy, 1 = Ill)                     | Integer |

### 2. **Faker-Based Streaming Simulator**

- **Source:** `src/vitals_kafka_producer.py`
- **Description:** Real-time JSON events simulating live patient vitals, emitted every second to a Kafka topic (`patient_vitals`).
- **Purpose:**
  - Emulates real-time device telemetry
  - Feeds Spark Structured Streaming for Delta Lake ETL and ML scoring

**Fields in Each Streamed JSON Record:**

| Field Name                                                                                   | Description                                             | Type    |
|----------------------------------------------------------------------------------------------|---------------------------------------------------------|---------|
| `patient_id`                                                                                 | Unique patient identifier (UUID)                        | String  |
| `timestamp`                                                                                  | Event timestamp in ISO 8601 (UTC)                       | String  |
| `birthday`                                                                                   | Patient date of birth (used to calculate age)           | String  |
| `gender`                                                                                     | Binary encoded gender (0 = Female, 1 = Male)            | Integer |
| `body_mass_index`                                                                            | BMI in kg/m²                                            | Float   |
| `body_temperature`                                                                           | Body temperature in °C                                  | Float   |
| `heart_rate`                                                                                 | Heart rate in beats per minute                          | Integer |
| `systolic_blood_pressure`                                                                    | Systolic blood pressure (mmHg)                          | Integer |
| `creatinine`                                                                                 | Creatinine level in mg/dL                               | Float   |
| `alanine_aminotransferase_[enzymatic_activity/volume]_in_serum_or_plasma`                   | ALT enzyme level in U/L                                 | Float   |
| `glucose`                                                                                    | Blood glucose level in mg/dL                            | Float   |
| `hemoglobin_[mass/volume]_in_blood`                                                          | Hemoglobin concentration in g/dL                        | Float   |
| `leukocytes_[#/volume]_in_blood_by_automated_count`                                          | White blood cell count (10³/μL)                         | Float   |
| `oxygen_saturation_in_arterial_blood`                                                        | Oxygen saturation percentage                            | Integer |

## Data Model
**Delta Lake Tables**

`bronze_patient_vitals`
- Raw data ingested from Kafka
- Schema: unvalidated, JSON

`silver_patient_vitals`
- Cleaned and parsed records
- Derived fields and simple alert flags

`gold_patient_summary`
- Aggregated vitals per patient
- Includes real-time anomaly detection score
- Partitioned by date and patient_id

**BigQuery Tables**
- Mirrors Gold layer
- Materialized views:
  - `patient_risk_scores`
  - `ward_alert_counts`
  - `vital_signs_hourly_trend`
 
## ML Model

**Goal:**  

Detect abnormal vital patterns in real time to alert clinicians.

**Algorithms Explored:**  
- **Isolation Forest** – Efficient unsupervised anomaly detection  
- **AutoEncoder** – Neural-network-based scoring (optional)  
- **LSTM** – Time-series anomaly detection (if needed)

**Workflow:**  
1. Train models on Synthea-generated historical data
2. Register model using MLflow (optional)
3. Inference in Spark Streaming pipeline
4. Append anomaly scores to Gold table
5. Visualize using Looker dashboards

## Project Files

1. `synthea_data/` – Contains static Synthea-generated patient demographics and vital signs in CSV/JSON format, including the transformed dataset used for training (`data_for_train.csv`).
2. `src/prepare_data.py` – Script for preparing the dataset for training.
3. `src/train_model.py` – Trains the anomaly detection model using static Synthea data, then saves the trained model.
4. `models/illness_classifier.pkl` – The serialized trained model, used for real-time streaming inference.
5. `src/vitals_kafka_producer.py` – Generates real-time vitals using Faker and sends them to a Kafka topic.
6. `delta_lake_setup/schema_bronze.json` – Delta Lake Bronze layer schema definition.
7. `delta_lake_setup/schema_silver.json` – Delta Lake Silver layer schema definition.
8. `delta_lake_setup/schema_gold.json` – Delta Lake Gold layer schema definition.
9. `src/spark_streaming_job.py` – Spark Structured Streaming job to read from Kafka, apply transformations, and write to Delta Lake (Bronze → Silver → Gold).
10. `src/ml_inference_stream.py` – Loads the trained model and performs real-time scoring on new patient vitals.
11. `src/bigquery_loader.py` – Transfers curated Gold layer vitals from Delta Lake to Google BigQuery for further analysis or reporting.
12. `dags/etl_pipeline.py` – Airflow DAG to orchestrate the streaming ETL flow from Kafka to Delta layers.
13. `notebooks/pipeline_walkthrough.ipynb` – Jupyter notebook for setup, environment config, and running key components of the pipeline.
14. `notebooks/visualization_insights.ipynb` – Jupyter notebook to visualize charts, detect trends, and present insights from Gold layer data (e.g., abnormal vitals, patient risk patterns).

## License

This project uses simulated patient data generated by Synthea, Faker, and custom scripts for educational and research purposes only. The data and dashboards are not based on real patients or real-world trends.

**Disclaimer:**

- The insights, trends, and anomalies presented in this project exist solely within the simulated environment. They should not be interpreted as medical findings, healthcare insights, or clinical recommendations. This project is intended to demonstrate a data engineering and analytics pipeline, not to represent real medical analysis.

- Do not use any of the generated reports, visualizations, or data for decision-making in real healthcare or diagnostics contexts.

---
